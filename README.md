This is the Jupyter Notebook version of the summary of loss functions from

[Machine Learning  Mastery](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/)

Tutorial Overview

This tutorial is divided into three parts; they are:

**Regression Loss Functions**
- [x] Mean Squared Error Loss
- [x] Mean Squared Logarithmic Error Loss
- [x] Mean Absolute Error Loss

**Binary Classification Loss Functions**
- [x] Binary Cross-Entropy
- [x] Hinge Loss
- [x] Squared Hinge Loss

**Multi-Class Classification Loss Functions**
- [x] Multi-Class Cross-Entropy Loss
- [x] Sparse Multiclass Cross-Entropy Loss
- [x] Kullback Leibler Divergence Loss


Env uses keras and tensforflow (v1)
